# near_real_time

## ğŸš€ Description du projet

**near_real_time** est un pipeline de donnÃ©es en quasi-temps rÃ©el, permettant dâ€™ingÃ©rer, traiter et stocker des donnÃ©es en continu.
Il est conÃ§u pour des cas comme lâ€™ingestion dâ€™Ã©vÃ©nements, le monitoring de flux, ou lâ€™alimentation de dashboards analytiques.
Le projet intÃ¨gre Ã©galement Airflow pour lâ€™orchestration des tÃ¢ches et Metabase pour la visualisation des donnÃ©es.

---

## ğŸ§© Architecture du projet

<img width="1436" height="591" alt="archi_proje_near" src="https://github.com/user-attachments/assets/c8ea0f9e-54ee-48a2-b4a4-fb27056d8b9a" />


- **Producer** : GÃ©nÃ¨re ou rÃ©cupÃ¨re les donnÃ©es et les envoie au broker.  
- **Broker (Kafka)** : File de messages pour bufferiser et transmettre les donnÃ©es.  
- **Consumer** : Consomme les messages, transforme les donnÃ©es et les stocke dans la base.  
- **Base de donnÃ©es (ClickHouse)** : Stockage analytique pour permettre des requÃªtes rapides.
- **Airflow (DAGs)** : Orchestration et planification des tÃ¢ches pour automatiser le pipeline.
- **Metabase** : Tableau de bord pour visualiser les donnÃ©es ingÃ©rÃ©es et analysÃ©es.

---

## ğŸ“‚ Structure du projet

<img width="485" height="539" alt="image" src="https://github.com/user-attachments/assets/58c61a2f-9ef5-4ceb-a9a7-499dfceb586a" />
near_real_time/
â”œâ”€â”€ clickhouse_data/       # Configurations ou donnÃ©es ClickHouse
â”œâ”€â”€ dags/                  # Orchestration / planification de tÃ¢ches Airflow
â”œâ”€â”€ jars/                  # Librairies Java
â”œâ”€â”€ scripts/               # Scripts utilitaires (initialisation, ingestionâ€¦)
â”œâ”€â”€ docker-compose.yml     # Orchestration Docker des services
â”œâ”€â”€ dockerfile.producer    # Dockerfile du producteur
â”œâ”€â”€ dockerfile.consumer    # Dockerfile du consommateur
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â”œâ”€â”€ wait-for-kafka.sh      # Script pour attendre Kafka
â”œâ”€â”€ wait-for-services.sh   # Script pour attendre tous les services
â””â”€â”€ metrics.json           # DÃ©finition des mÃ©triques

![WhatsApp Image 2025-10-10 Ã  00 36 42_42f4f620](https://github.com/user-attachments/assets/73f445d9-9c12-46f4-a804-461e30379875)
![WhatsApp Image 2025-10-10 Ã  00 42 09_dbca6eb4](https://github.com/user-attachments/assets/bb94a936-1fd3-4c3a-840f-978044ee5bf4)
![WhatsApp Image 2025-10-10 Ã  00 42 36_f100a0b6](https://github.com/user-attachments/assets/82c8b978-81b3-4946-9164-2f2293f6ac0d)
![WhatsApp Image 2025-10-10 Ã  00 47 03_cd83a268](https://github.com/user-attachments/assets/d1fc6085-9f74-473d-b4b3-fa3cd7d58660)




---

## ğŸ›  PrÃ©requis

- Docker et Docker Compose
- Python (si utilisation des scripts Python)
- Ports libres pour Kafka, ClickHouse, Airflow et Metabase
- AccÃ¨s au navigateur pour Metabase


---

## ğŸš€ Installation et exÃ©cution

1. Cloner le dÃ©pÃ´t :  
```bash
git clone https://github.com/SalmaTAMMARI12/near_real_time.git
cd near_real_time
2. Construire et lancer tous les services avec Docker Compose
Construire et lancer les services
docker-compose up --build
Les scripts **wait-for-kafka.sh** et **wait-for-services.sh** garantissent que tous les services sont prÃªts avant de dÃ©marrer les producers et consumers.
